import time
import json
import os
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

os.chdir(os.path.dirname(__file__))

# í¬ë¡¬ ì˜µì…˜ ì„¤ì •
options = Options()
user_agent = (
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
    "AppleWebKit/537.36 (KHTML, like Gecko) "
    "Chrome/114.0.0.0 Safari/537.36"
)
options.add_argument(f"user-agent={user_agent}")
options.add_argument("--headless")  # í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ (ë¸Œë¼ìš°ì € ì°½ ì•ˆ ëœ¨ê²Œ í•¨)
options.add_experimental_option("excludeSwitches", ["enable-automation"])
options.add_experimental_option('useAutomationExtension', False)
options.add_argument("--disable-blink-features=AutomationControlled")
options.add_argument("--window-size=1920,1080")  

driver = webdriver.Chrome(options=options)

def get_data(nm):
    print("ğŸš€ ë„¤ì´ë²„ ì§€ë„ í˜ì´ì§€ ì ‘ì† ì¤‘...")
    driver.get("https://map.naver.com/p/search/ì„œëŒ€ë¬¸êµ¬ ë§›ì§‘?c=13.00,0,0,0,dh")
    time.sleep(1)

    # ê²€ìƒ‰ê²°ê³¼ iframe ì§„ì…
    search_frame = driver.find_element(By.ID, 'searchIframe')
    driver.switch_to.frame(search_frame)

    # ìŠ¤í¬ë¡¤ í•˜ì—¬ ìŒì‹ì  ë¦¬ìŠ¤íŠ¸ ëª¨ë‘ ë¡œë”©
    scrollable_element = driver.find_element(By.XPATH, '//*[@id="_pcmap_list_scroll_container"]')
    last_height = driver.execute_script("return arguments[0].scrollHeight", scrollable_element)

    scroll_count = 0
    while True:
        driver.execute_script("arguments[0].scrollTop += 1200;", scrollable_element)
        time.sleep(1)
        new_height = driver.execute_script("return arguments[0].scrollHeight", scrollable_element)
        if new_height == last_height:
            break
        last_height = new_height
        scroll_count += 1
        print(f"ğŸ”„ ìŠ¤í¬ë¡¤ {scroll_count}íšŒì°¨ ì™„ë£Œ")

    reviews = {}
    restaurants = driver.find_elements(By.CSS_SELECTOR, 'li[data-laim-exp-id="undefinedundefined"]')
    print(f"ğŸ“‹ ìˆ˜ì§‘ ëŒ€ìƒ ìŒì‹ì  ìˆ˜: {len(restaurants)}ê°œ")

    for index, li in enumerate(restaurants):
        try:
            name_elem = li.find_element(By.XPATH, ".//div[1]/div[1]/a/span[contains(@class, 'TYaxT')]")
            category_elem = li.find_element(By.XPATH, ".//div[1]/div[1]/a/span[contains(@class, 'KCMnt')]")
            button = li.find_element(By.XPATH, ".//div[1]/div[1]/a")
        except Exception as e:
            print(f"âŒ [{index+1}] ìŒì‹ì  ìš”ì†Œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            continue

        name = name_elem.text.strip()
        category = category_elem.text.strip()
        print(f"â–¶ {index+1}/{len(restaurants)}: {name} ({category})")

        reviews[name] = {"category": category}

        # ìƒì„¸ í˜ì´ì§€ í´ë¦­
        try:
            button.click()
            time.sleep(2)
            driver.switch_to.default_content()
            driver.switch_to.frame(driver.find_element(By.ID, 'entryIframe'))

            # ë¦¬ë·° íƒ­ í´ë¦­
            try:
                parent = WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.XPATH, '//*[@id="app-root"]/div/div/div/div[4]/div/div/div/div'))
                )
                tab_links = parent.find_elements(By.TAG_NAME, 'a')
                for tab in tab_links:
                    if "ë¦¬ë·°" in tab.text:
                        tab.click()
                        break
            except:
                print("   âš ï¸ ë¦¬ë·° íƒ­ ì—†ìŒ â€” ìŠ¤í‚µ")
                continue

            # ë¦¬ë·° ìˆ˜ì§‘ (ìµœëŒ€ 10ê°œ)
            comments = []
            time.sleep(2)
            try:
                review_items = WebDriverWait(driver, 5).until(
                    EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'ul li'))
                )
            except:
                review_items = []

            for li in review_items[:10]:
                try:
                    text = li.text.strip()
                    if text:
                        comments.append(text)
                except:
                    continue

            reviews[name]["comment"] = comments
            print(f"   âœ” ë¦¬ë·° {len(comments)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")

        except Exception as e:
            print(f"   âŒ ìƒì„¸ í˜ì´ì§€ ìˆ˜ì§‘ ì¤‘ ì—ëŸ¬: {e}")
            continue

        finally:
            driver.switch_to.default_content()
            driver.switch_to.frame(search_frame)

    # ê²°ê³¼ ì €ì¥
    with open('reviews_NM.json', 'w', encoding='utf-8') as f:
        json.dump(reviews, f, ensure_ascii=False, indent=4)

    print("\nâœ… ëª¨ë“  ìŒì‹ì  ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ ë° ì €ì¥ ì™„ë£Œ!")

# ì‹¤í–‰
get_NM_data()
